{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> Project 2\n",
    "\n",
    "Project Description:\n",
    "- Use same datasets as Project 1.\n",
    "- Preprocess data: Explore data and apply data scaling.\n",
    "\n",
    "Classification Task:\n",
    "- Apply two voting classifiers - one with hard voting and one with soft voting\n",
    "- Apply any two models with bagging and any two models with pasting.\n",
    "- Apply any two models with adaboost boosting\n",
    "- Apply one model with gradient boosting\n",
    "- Apply PCA on data and then apply all the models in project 1 again on data you get from PCA. Compare your results with results in project 1. You don't need to apply all the models twice. Just copy the result table from project 1, prepare similar table for all the models after PCA and compare both tables. Does PCA help in getting better results?\n",
    "- Apply deep learning models covered in class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|No|Variables|Description|\n",
    "|:--|:--------|:-----------|\n",
    "|1|customerID|Customer ID|\n",
    "|2|gender|Whether the customer is a male or a female|\n",
    "|3|SeniorCitizen|senior citizen or not (1, 0)|\n",
    "|4|Dependents|Whether the customer has a partner or not (Yes, No)|\n",
    "|5|tenure|Number of months the customer has stayed with the company|\n",
    "|6|PhoneService| Whether the customer has a phone service or not (Yes, No)|\n",
    "|7|MultipleLines|Whether the customer has multiple lines or not (Yes, No, No phone service)|\n",
    "|8| InternetService|Customer’s internet service provider (DSL, Fiber optic, No)|\n",
    "|9| OnlineSecurity|Whether the customer has online security or not (Yes, No, No internet service)|\n",
    "|10| OnlineBackup|Whether the customer has online backup or not (Yes, No, No internet service)|\n",
    "|11| DeviceProtection|Whether the customer has device protection or not (Yes, No, No internet service)|\n",
    "|12|TechSupport|Whether the customer has tech support or not (Yes, No, No internet service)|\n",
    "|13|StreamingTV|Whether the customer has streaming TV or not (Yes, No, No internet service)|\n",
    "|14|StreamingMovies|Whether the customer has streaming movies or not (Yes, No, No internet service)|\n",
    "|15|Contract|The contract term of the customer (Month-to-month, One year, Two year)|\n",
    "|16|PaperlessBilling|Whether the customer has paperless billing or not (Yes, No)|\n",
    "|17|PaymentMethod|The customer’s payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))|\n",
    "|18|MonthlyCharges|The amount charged to the customer monthly|\n",
    "|19|TotalCharges|The total amount charged to the customer|\n",
    "|20|Churn |Whether the customer churned or not (Yes or No)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 22 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Unnamed: 0        7043 non-null   int64  \n",
      " 1   customerID        7043 non-null   object \n",
      " 2   gender            7043 non-null   object \n",
      " 3   SeniorCitizen     7043 non-null   int64  \n",
      " 4   Partner           7043 non-null   object \n",
      " 5   Dependents        6845 non-null   object \n",
      " 6   tenure            7043 non-null   int64  \n",
      " 7   PhoneService      7043 non-null   object \n",
      " 8   MultipleLines     7043 non-null   object \n",
      " 9   InternetService   7043 non-null   object \n",
      " 10  OnlineSecurity    7043 non-null   object \n",
      " 11  OnlineBackup      7043 non-null   object \n",
      " 12  DeviceProtection  6761 non-null   object \n",
      " 13  TechSupport       6722 non-null   object \n",
      " 14  StreamingTV       7043 non-null   object \n",
      " 15  StreamingMovies   7043 non-null   object \n",
      " 16  Contract          7043 non-null   object \n",
      " 17  PaperlessBilling  7043 non-null   object \n",
      " 18  PaymentMethod     7043 non-null   object \n",
      " 19  MonthlyCharges    7043 non-null   float64\n",
      " 20  TotalCharges      7032 non-null   float64\n",
      " 21  Churn             7043 non-null   object \n",
      "dtypes: float64(2), int64(3), object(17)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "telco = pd.read_csv(\"telco_o.csv\", na_values=['?', ' '])\n",
    "telco.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependents          198\n",
      "DeviceProtection    282\n",
      "TechSupport         321\n",
      "TotalCharges         11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "telco_na = telco.isnull().sum()\n",
    "print(telco_na[telco_na>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco.drop(['customerID'], axis=1, inplace=True)\n",
    "\n",
    "grps = telco.groupby(['Contract', 'MultipleLines'])\n",
    "telco['DeviceProtection'] = grps['DeviceProtection'].transform(lambda grp: grp.fillna(grp.value_counts().index[0]))\n",
    "\n",
    "grps = telco.groupby(['MultipleLines'])\n",
    "telco['TechSupport'] = grps['TechSupport'].transform(lambda grp: grp.fillna(grp.value_counts().index[0]))\n",
    "\n",
    "telco.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert categorical features to numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco[\"Churn\"] = telco[\"Churn\"].map({\"No\":0, \"Yes\":1}).astype(int)\n",
    "telco['gender'] = telco['gender'].map({\"Female\": 0, \"Male\":1}).astype(int)\n",
    "telco[\"Partner\"] = telco[\"Partner\"].map({\"Yes\": 1, \"No\": 0}).astype(int)\n",
    "telco['PhoneService'] = telco['PhoneService'].map({\"Yes\":1, \"No\":0}).astype(int)\n",
    "telco[\"MultipleLines\"] = telco[\"MultipleLines\"].map({\"No phone service\":0, \"No\":1, \"Yes\":2}).astype(int)\n",
    "telco[\"OnlineSecurity\"] = telco[\"OnlineSecurity\"].map({\"No internet service\":0, \"No\":1, \"Yes\":2}).astype(int)\n",
    "telco[\"OnlineBackup\"] = telco[\"OnlineBackup\"].map({\"No internet service\":0, \"No\":1, \"Yes\":2}).astype(int)\n",
    "telco[\"StreamingMovies\"] = telco[\"StreamingMovies\"].map({\"No internet service\":0, \"No\":1, \"Yes\":2}).astype(int)\n",
    "telco[\"PaperlessBilling\"] = telco[\"PaperlessBilling\"].map({\"No\":0, \"Yes\":1}).astype(int)\n",
    "telco['DeviceProtection'] = telco['DeviceProtection'].map({'No internet service':0, \"No\":1, \"Yes\":2}).astype(int)\n",
    "telco[\"Dependents\"] = telco[\"Dependents\"].map({\"Yes\": 1, \"No\": 0}, na_action='ignore').astype(int)\n",
    "telco['TechSupport'] = telco['TechSupport'].map({'No internet service':0, 'No':1, 'Yes':2}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add dummy variables for InternetService column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "its_dummy = pd.get_dummies(telco['InternetService'], columns='InternetService', prefix='ITS') \n",
    "telco = pd.concat([telco, its_dummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "telco.drop(['InternetService'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stv_dummy = pd.get_dummies(telco['StreamingTV'], columns='StreamingTV', prefix='STV')\n",
    "telco = pd.concat([telco, stv_dummy], axis=1)\n",
    "telco.drop(['StreamingTV'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "smv_dummy = pd.get_dummies(telco['StreamingMovies'], columns='StreamingMovies', prefix='SMV')\n",
    "telco = pd.concat([telco, smv_dummy], axis=1)\n",
    "telco.drop(['StreamingMovies'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_dummy = pd.get_dummies(telco['Contract'], columns='Contract', prefix='CTRT')\n",
    "telco = pd.concat([telco, con_dummy], axis=1)\n",
    "telco.drop(['Contract'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_dummy = pd.get_dummies(telco['PaymentMethod'], columns='PaymentMethod', prefix='Payment')\n",
    "telco = pd.concat([telco, payment_dummy], axis=1)\n",
    "telco.drop(['PaymentMethod'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert interger-string column TotalCharge to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         29.85\n",
       "1       1889.50\n",
       "2        108.15\n",
       "3       1840.75\n",
       "4        151.65\n",
       "         ...   \n",
       "7038    1990.50\n",
       "7039    7362.90\n",
       "7040     346.45\n",
       "7041     306.60\n",
       "7042    6844.50\n",
       "Name: TotalCharges, Length: 6834, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_numeric(telco['TotalCharges'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we have a data frame without missing values and all features have numeric value type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6834 entries, 0 to 7042\n",
      "Data columns (total 32 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Unnamed: 0                         6834 non-null   int64  \n",
      " 1   gender                             6834 non-null   int32  \n",
      " 2   SeniorCitizen                      6834 non-null   int64  \n",
      " 3   Partner                            6834 non-null   int32  \n",
      " 4   Dependents                         6834 non-null   int32  \n",
      " 5   tenure                             6834 non-null   int64  \n",
      " 6   PhoneService                       6834 non-null   int32  \n",
      " 7   MultipleLines                      6834 non-null   int32  \n",
      " 8   OnlineSecurity                     6834 non-null   int32  \n",
      " 9   OnlineBackup                       6834 non-null   int32  \n",
      " 10  DeviceProtection                   6834 non-null   int32  \n",
      " 11  TechSupport                        6834 non-null   int32  \n",
      " 12  PaperlessBilling                   6834 non-null   int32  \n",
      " 13  MonthlyCharges                     6834 non-null   float64\n",
      " 14  TotalCharges                       6834 non-null   float64\n",
      " 15  Churn                              6834 non-null   int32  \n",
      " 16  ITS_DSL                            6834 non-null   uint8  \n",
      " 17  ITS_Fiber optic                    6834 non-null   uint8  \n",
      " 18  ITS_No                             6834 non-null   uint8  \n",
      " 19  STV_No                             6834 non-null   uint8  \n",
      " 20  STV_No internet service            6834 non-null   uint8  \n",
      " 21  STV_Yes                            6834 non-null   uint8  \n",
      " 22  SMV_0                              6834 non-null   uint8  \n",
      " 23  SMV_1                              6834 non-null   uint8  \n",
      " 24  SMV_2                              6834 non-null   uint8  \n",
      " 25  CTRT_Month-to-month                6834 non-null   uint8  \n",
      " 26  CTRT_One year                      6834 non-null   uint8  \n",
      " 27  CTRT_Two year                      6834 non-null   uint8  \n",
      " 28  Payment_Bank transfer (automatic)  6834 non-null   uint8  \n",
      " 29  Payment_Credit card (automatic)    6834 non-null   uint8  \n",
      " 30  Payment_Electronic check           6834 non-null   uint8  \n",
      " 31  Payment_Mailed check               6834 non-null   uint8  \n",
      "dtypes: float64(2), int32(11), int64(3), uint8(16)\n",
      "memory usage: 720.8 KB\n"
     ]
    }
   ],
   "source": [
    "telco.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Project 1 Result Table <br>\n",
    "\n",
    "|No|Classifiers|Best Parameters|Accuary Score|Best Model|\n",
    "|:--|:-----------|:---------------|:-------------|:----------|\n",
    "|1|KNN|k=18|0.774|\n",
    "|2|Logistic Regression|c = 0.1, penalty = l2|0.801|\n",
    "|3|Softmax Regression|c = 0.01|0.802|\n",
    "|4|Linear SVM|c = 0.01|0.803|<b>Yes|\n",
    "|5|SVM with Kernel Linear|c=0.01|0.800| \n",
    "|6|SVM with Kernel RBF|c=1, gamma=0.1|0.800|\n",
    "|7|SVM with Kernel Polynomial|degree=3, c=0.1|0.798|\n",
    "|8|Decision Tree|depth=3|0.791|<b>*|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Train, Validation and Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = telco['Churn']\n",
    "X = telco.drop(['Churn'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test_org, y_train_full, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)\n",
    "\n",
    "X_train_org, X_valid_org, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train_org)\n",
    "X_valid = scaler.transform(X_valid_org)\n",
    "X_test = scaler.transform(X_test_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size:  (3826, 31) \n",
      "validation dataset size:  (1641, 31) \n",
      "test dataset size:  (1367, 31)\n"
     ]
    }
   ],
   "source": [
    "print(\"train dataset size: \", X_train.shape, \"\\nvalidation dataset size: \", X_valid.shape, \"\\ntest dataset size: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Apply two voting classifiers (Hard & Soft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For **Hard Voting Classifiers**, we choose **Logistic Regression, KNN, Linear SVM** to evaluate.\n",
    "- For **Soft Coting Classifiers**, we choose **SVM with Kernel Linear, SVM with Kernel RBF and Decision Tree** to evaluate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Voting Classifiers (Hard): Logistic Regression, KNN, Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.7966\n",
      "KNeighborsClassifier 0.7747\n",
      "LinearSVC 0.7981\n",
      "VotingClassifier 0.7974\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "log_clf = LogisticRegression(C=0.1, penalty='l2')\n",
    "\n",
    "# KNN\n",
    "knn_clf = KNeighborsClassifier(18)\n",
    "\n",
    "# Linear SVM\n",
    "lsvm_clf = LinearSVC(C=0.01)\n",
    "\n",
    "voting1_clf = VotingClassifier(estimators=[('lr', log_clf), ('knn', knn_clf), ('lsvc', lsvm_clf)], voting='hard')\n",
    "\n",
    "for clf in (log_clf, knn_clf, lsvm_clf, voting1_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, round(accuracy_score(y_test, y_pred), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Scores.append({'Model Type':'Classification',\n",
    "                    'Model Name': 'Hard Voting Classifier',\n",
    "                    'Best Parameters': '',\n",
    "                    'Train Score': voting1_clf.score(X_train, y_train),\n",
    "                    'Test Score': voting1_clf.score(X_test, y_test)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The accuracy score of **Hard Voting Classifier** is **0.7974**, higher than **K Neighbors Classifier**, and similar to **Logistic Regression** and **Linear SVC**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Voting Classifier (Soft): SVM with Kernel Linear, Logistic Regreesion, Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC 0.7857\n",
      "LogisticRegression 0.7966\n",
      "DecisionTreeClassifier 0.7805\n",
      "VotingClassifier 0.7915\n"
     ]
    }
   ],
   "source": [
    "# SVM with Kernel Linear\n",
    "svmkl_clf = SVC(kernel='linear', C=0.01, probability=True)\n",
    "svmkl_clf.fit(X_train, y_train)\n",
    "\n",
    "# Logistic Regression\n",
    "log_clf = LogisticRegression(C=0.1, penalty='l2')\n",
    "log_clf.fit(X_train, y_train)\n",
    "\n",
    "# Decsion Tree\n",
    "dt_clf = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "voting2_clf = VotingClassifier(estimators=[('svmkl', svmkl_clf), ('log', log_clf), ('dt', dt_clf)], voting='soft')\n",
    "voting2_clf.fit(X_train, y_train)\n",
    "\n",
    "for clf in (svmkl_clf, log_clf, dt_clf, voting2_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, round(accuracy_score(y_test, y_pred), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Scores.append({'Model Type':'Classification',\n",
    "                    'Model Name': 'Soft Voting Classifier',\n",
    "                    'Best Parameters': '',\n",
    "                    'Train Score': voting2_clf.score(X_train, y_train),\n",
    "                    'Test Score': voting2_clf.score(X_test, y_test)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The accuracy score of **Soft Voting Classifier** is **0.7915**, higher than **SVM with kernel linear** and **Decision Tree classifier**, and slightly lower than **Logistic Regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Apply two models with bagging and two models with pasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On the **Bagging** part, we choose **KNN** and **Decision Tree** as the base model.\n",
    "- On the **Pasting** part, we choose **Logistic Regression** and **Linear SVM** as the base model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bagging with KNN as base model(k=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from  sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=BaggingClassifier(base_estimator=KNeighborsClassifier(algorithm='auto',\n",
       "                                                                             leaf_size=30,\n",
       "                                                                             metric='minkowski',\n",
       "                                                                             metric_params=None,\n",
       "                                                                             n_jobs=None,\n",
       "                                                                             n_neighbors=18,\n",
       "                                                                             p=2,\n",
       "                                                                             weights='uniform'),\n",
       "                                         bootstrap=True,\n",
       "                                         bootstrap_features=False,\n",
       "                                         max_features=1.0, max_samples=1.0,\n",
       "                                         n_estimators=10, n_jobs=None,\n",
       "                                         oob_score=False, random_state=0,\n",
       "                                         verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_samples': [0.5, 0.7], 'n_estimators': [50, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(18)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "param1 = {\n",
    "    'n_estimators': [50, 100], \n",
    "    'max_samples':[0.5, 0.7]\n",
    "}\n",
    "\n",
    "bag_knn = BaggingClassifier(knn_clf, bootstrap=True, random_state=0)\n",
    "grid1 = GridSearchCV(bag_knn, param1, cv = 5, n_jobs = -1, return_train_score= True)\n",
    "grid1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters : {'max_samples': 0.5, 'n_estimators': 100}\n",
      "Best score with the parameters : 0.78\n"
     ]
    }
   ],
   "source": [
    "print('Best model parameters : ' + str(grid1.best_params_))\n",
    "print('Best score with the parameters : {:.2f}'.format(grid1.best_score_))\n",
    "bag_knn = grid1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.7956\n",
      "Validation score: 0.7885\n"
     ]
    }
   ],
   "source": [
    "bknn_train_score = bag_knn.score(X_train, y_train)\n",
    "bknn_valid_score = bag_knn.score(X_valid, y_valid)\n",
    "print('Train score: {:.4f}'.format(bknn_train_score))\n",
    "print('Validation score: {:.4f}'.format(bknn_valid_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of KNN Classifier (k=18) is: 0.7747\n",
      "The accuracy score of Bagging with KNN Classifier (k=18) is: 0.7827\n"
     ]
    }
   ],
   "source": [
    "knn_acu = knn_clf.score(X_test, y_test)\n",
    "print(\"The accuracy score of KNN Classifier (k=18) is: {:.4f}\".format(knn_acu))\n",
    "bknn_acu = bag_knn.score(X_test, y_test)\n",
    "print(\"The accuracy score of Bagging with KNN Classifier (k=18) is: {:.4f}\".format(bknn_acu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Scores.append({'Model Type':'Classification',\n",
    "                    'Model Name': 'Bagging with KNeighbor Classifier',\n",
    "                    'Best Parameters': grid1.best_params_,\n",
    "                    'Train Score': bag_knn.score(X_train, y_train),\n",
    "                    'Test Score': bag_knn.score(X_test, y_test)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Bagging with KNN** gets a higher score **(0.7827)** than **KNN (0.7747)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bagging with Decision Tree as base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=BaggingClassifier(base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                                               class_weight=None,\n",
       "                                                                               criterion='gini',\n",
       "                                                                               max_depth=3,\n",
       "                                                                               max_features=None,\n",
       "                                                                               max_leaf_nodes=None,\n",
       "                                                                               min_impurity_decrease=0.0,\n",
       "                                                                               min_impurity_split=None,\n",
       "                                                                               min_samples_leaf=1,\n",
       "                                                                               min_samples_split=2,\n",
       "                                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                                               presort='deprecated',\n",
       "                                                                               random_state=0,\n",
       "                                                                               splitter='best'),\n",
       "                                         bootstrap=True,\n",
       "                                         bootstrap_features=False,\n",
       "                                         max_features=1.0, max_samples=1.0,\n",
       "                                         n_estimators=10, n_jobs=None,\n",
       "                                         oob_score=False, random_state=0,\n",
       "                                         verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_samples': [0.5, 0.7], 'n_estimators': [50, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "param2 = {'n_estimators': [50, 100], 'max_samples': [0.5, 0.7]}\n",
    "\n",
    "bag_dt = BaggingClassifier(dt_clf, bootstrap=True, random_state=0)\n",
    "grid2 = GridSearchCV(bag_dt, param2, cv=5, n_jobs = -1, return_train_score= True)\n",
    "grid2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters : {'max_samples': 0.5, 'n_estimators': 50}\n",
      "Best score with the parameters : 0.79\n"
     ]
    }
   ],
   "source": [
    "print('Best model parameters : ' + str(grid2.best_params_))\n",
    "print('Best score with the parameters : {:.2f}'.format(grid2.best_score_))\n",
    "bag_dt = grid2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.7948\n",
      "Validation score: 0.7873\n"
     ]
    }
   ],
   "source": [
    "bdt_train_score = bag_dt.score(X_train, y_train)\n",
    "bdt_valid_score = bag_dt.score(X_valid, y_valid)\n",
    "\n",
    "print('Train score: {:.4f}'.format(bdt_train_score))\n",
    "print('Validation score: {:.4f}'.format(bdt_valid_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of Decision Tree is: 0.7805\n",
      "The accuracy score of Bagging with Decison Tree is: 0.7791\n"
     ]
    }
   ],
   "source": [
    "dt_acu = dt_clf.score(X_test, y_test)\n",
    "print(\"The accuracy score of Decision Tree is: {:.4f}\".format(dt_acu))\n",
    "\n",
    "bdt_acu = bag_dt.score(X_test, y_test)\n",
    "print(\"The accuracy score of Bagging with Decison Tree is: {:.4f}\".format(bdt_acu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Scores.append({'Model Type':'Classification',\n",
    "                    'Model Name': 'Bagging with Decision Tree',\n",
    "                    'Best Parameters': grid2.best_params_,\n",
    "                    'Train Score': bag_dt.score(X_train, y_train),\n",
    "                    'Test Score': bag_dt.score(X_test, y_test)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Bagging with Decision Tree** gets a similar score **(0.7791)** to **Decision Tree (0.7805)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pasting Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pasting with Logistic Regression as base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=BaggingClassifier(base_estimator=LogisticRegression(C=0.1,\n",
       "                                                                           class_weight=None,\n",
       "                                                                           dual=False,\n",
       "                                                                           fit_intercept=True,\n",
       "                                                                           intercept_scaling=1,\n",
       "                                                                           l1_ratio=None,\n",
       "                                                                           max_iter=100,\n",
       "                                                                           multi_class='auto',\n",
       "                                                                           n_jobs=None,\n",
       "                                                                           penalty='l2',\n",
       "                                                                           random_state=None,\n",
       "                                                                           solver='lbfgs',\n",
       "                                                                           tol=0.0001,\n",
       "                                                                           verbose=0,\n",
       "                                                                           warm_start=False),\n",
       "                                         bootstrap=False,\n",
       "                                         bootstrap_features=False,\n",
       "                                         max_features=1.0, max_samples=1.0,\n",
       "                                         n_estimators=10, n_jobs=None,\n",
       "                                         oob_score=False, random_state=0,\n",
       "                                         verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_samples': [0.5, 0.7], 'n_estimators': [50, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param3  = {'n_estimators': [50, 100], 'max_samples': [0.5, 0.7]}\n",
    "\n",
    "bag_log = BaggingClassifier(log_clf, bootstrap=False, random_state=0)\n",
    "grid3 = GridSearchCV(bag_log, param3, cv=5, n_jobs = -1, return_train_score= True)\n",
    "grid3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters : {'max_samples': 0.7, 'n_estimators': 50}\n",
      "Best score with the parameters : 0.80\n"
     ]
    }
   ],
   "source": [
    "print('Best model parameters : ' + str(grid3.best_params_))\n",
    "print('Best score with the parameters : {:.2f}'.format(grid3.best_score_))\n",
    "bag_log = grid3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8006\n",
      "Validation score: 0.8001\n"
     ]
    }
   ],
   "source": [
    "blog_train_score = bag_log.score(X_train, y_train)\n",
    "blog_valid_score = bag_log.score(X_valid, y_valid)\n",
    "\n",
    "print('Train score: {:.4f}'.format(blog_train_score))\n",
    "print('Validation score: {:.4f}'.format(blog_valid_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of Logistic Regression Classifier is: 0.7966\n",
      "The accuracy score of Pasting with Logistic Regression Classifier is: 0.7974\n"
     ]
    }
   ],
   "source": [
    "log_acu = log_clf.score(X_test, y_test)\n",
    "print(\"The accuracy score of Logistic Regression Classifier is: {:.4f}\".format(log_acu))\n",
    "\n",
    "blog_acu = bag_log.score(X_test, y_test)\n",
    "print(\"The accuracy score of Pasting with Logistic Regression Classifier is: {:.4f}\".format(blog_acu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Scores.append({'Model Type':'Classification',\n",
    "                    'Model Name': 'Pasting with Logistic Regression',\n",
    "                    'Best Parameters': grid3.best_params_,\n",
    "                    'Train Score': bag_log.score(X_train, y_train),\n",
    "                    'Test Score': bag_log.score(X_test, y_test)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Pasting with Logistic Regression** gets a score **(0.7974)** slightly higher than **Logistic Regression (0.7966)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Pasting with Linear SVM as base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=BaggingClassifier(base_estimator=LinearSVC(C=0.01,\n",
       "                                                                  class_weight=None,\n",
       "                                                                  dual=True,\n",
       "                                                                  fit_intercept=True,\n",
       "                                                                  intercept_scaling=1,\n",
       "                                                                  loss='squared_hinge',\n",
       "                                                                  max_iter=1000,\n",
       "                                                                  multi_class='ovr',\n",
       "                                                                  penalty='l2',\n",
       "                                                                  random_state=None,\n",
       "                                                                  tol=0.0001,\n",
       "                                                                  verbose=0),\n",
       "                                         bootstrap=False,\n",
       "                                         bootstrap_features=False,\n",
       "                                         max_features=1.0, max_samples=1.0,\n",
       "                                         n_estimators=10, n_jobs=None,\n",
       "                                         oob_score=False, random_state=0,\n",
       "                                         verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_samples': [0.5, 0.7], 'n_estimators': [50, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param4  = {'n_estimators': [50, 100], 'max_samples': [0.5, 0.7]}\n",
    "\n",
    "bag_lsvm = BaggingClassifier(lsvm_clf, bootstrap=False, random_state=0)\n",
    "grid4 = GridSearchCV(bag_lsvm, param4, cv=5, n_jobs = -1, return_train_score= True)\n",
    "grid4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters : {'max_samples': 0.7, 'n_estimators': 50}\n",
      "Best score with the parameters : 0.80\n"
     ]
    }
   ],
   "source": [
    "print('Best model parameters : ' + str(grid4.best_params_))\n",
    "print('Best score with the parameters : {:.2f}'.format(grid4.best_score_))\n",
    "bag_lsvm = grid4.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8006\n",
      "Validation score: 0.8001\n"
     ]
    }
   ],
   "source": [
    "blog_train_score = bag_log.score(X_train, y_train)\n",
    "blog_valid_score = bag_log.score(X_valid, y_valid)\n",
    "print('Train score: {:.4f}'.format(blog_train_score))\n",
    "print('Validation score: {:.4f}'.format(blog_valid_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of Linear SVM is: 0.7981\n",
      "The accuracy score of Pasting with Linear SVM is: 0.7959\n"
     ]
    }
   ],
   "source": [
    "y_pred_lsvm = lsvm_clf.predict(X_test)\n",
    "lsvm_acu = lsvm_clf.score(X_test, y_test)\n",
    "print(\"The accuracy score of Linear SVM is: {:.4f}\".format(lsvm_acu))\n",
    "\n",
    "blsvm_acu = bag_lsvm.score(X_test, y_test)\n",
    "print(\"The accuracy score of Pasting with Linear SVM is: {:.4f}\".format(blsvm_acu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Scores.append({'Model Type':'Classification',\n",
    "                    'Model Name': 'Pasting with Linear SVM',\n",
    "                    'Best Parameters': grid4.best_params_,\n",
    "                    'Train Score': bag_lsvm.score(X_train, y_train),\n",
    "                    'Test Score': bag_lsvm.score(X_test, y_test)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Pasting with Linear SVM** get a similar score **(0.7959)** to **Linear SVM (0.7981)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Apply two models with adaboost boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On this part, we choose **Decision Tree** and **SVM with Kernel Linear** as the base model of adaboost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Adaboost with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                          base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                                                class_weight=None,\n",
       "                                                                                criterion='gini',\n",
       "                                                                                max_depth=3,\n",
       "                                                                                max_features=None,\n",
       "                                                                                max_leaf_nodes=None,\n",
       "                                                                                min_impurity_decrease=0.0,\n",
       "                                                                                min_impurity_split=None,\n",
       "                                                                                min_samples_leaf=1,\n",
       "                                                                                min_samples_split=2,\n",
       "                                                                                min_weight_fraction_leaf=0.0,\n",
       "                                                                                presort='deprecated',\n",
       "                                                                                random_state=0,\n",
       "                                                                                splitter='best'),\n",
       "                                          learning_rate=1.0, n_estimators=50,\n",
       "                                          random_state=None),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.5, 0.7],\n",
       "                         'n_estimators': [100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_dt = AdaBoostClassifier(dt_clf)\n",
    "param5 = { \n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.5, 0.7]\n",
    "}\n",
    "\n",
    "grid5 = GridSearchCV(ada_dt, param5, cv= 5, n_jobs=-1)\n",
    "grid5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters : {'learning_rate': 0.5, 'n_estimators': 100}\n",
      "Best score with the parameters : 0.7543\n"
     ]
    }
   ],
   "source": [
    "print('Best model parameters : ' + str(grid5.best_params_))\n",
    "print('Best score with the parameters : {:.4f}'.format(grid5.best_score_))\n",
    "ada_dt = grid5.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9151\n",
      "Validation score: 0.7782\n"
     ]
    }
   ],
   "source": [
    "ada1_train_score = ada_dt.score(X_train, y_train)\n",
    "ada1_valid_score = ada_dt.score(X_valid, y_valid)\n",
    "print('Train score: {:.4f}'.format(ada1_train_score))\n",
    "print('Validation score: {:.4f}'.format(ada1_valid_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of Decision Tree is: 0.7805\n",
      "The accuracy score of adaboost with Decision Tree is: 0.7505\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy score of Decision Tree is: {:.4f}\".format(dt_acu))\n",
    "\n",
    "ada1_acu = ada_dt.score(X_test, y_test)\n",
    "print(\"The accuracy score of adaboost with Decision Tree is: {:.4f}\".format(ada1_acu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Scores.append({'Model Type':'Classification',\n",
    "                    'Model Name': 'Adaboosting with Decision Tree',\n",
    "                    'Best Parameters': grid5.best_params_,\n",
    "                    'Train Score': ada_dt.score(X_train, y_train),\n",
    "                    'Test Score': ada_dt.score(X_test, y_test)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Adaboost with Decision Tree** gets a score **(0.7505)** slightly lower than **Decision Tree (0.7805)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Adaboost with SVM with Kernel Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                          base_estimator=SVC(C=0.01,\n",
       "                                                             break_ties=False,\n",
       "                                                             cache_size=200,\n",
       "                                                             class_weight=None,\n",
       "                                                             coef0=0.0,\n",
       "                                                             decision_function_shape='ovr',\n",
       "                                                             degree=3,\n",
       "                                                             gamma='scale',\n",
       "                                                             kernel='linear',\n",
       "                                                             max_iter=-1,\n",
       "                                                             probability=True,\n",
       "                                                             random_state=None,\n",
       "                                                             shrinking=True,\n",
       "                                                             tol=0.001,\n",
       "                                                             verbose=False),\n",
       "                                          learning_rate=1.0, n_estimators=50,\n",
       "                                          random_state=None),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.5, 0.7],\n",
       "                         'n_estimators': [100, 150]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_skl = AdaBoostClassifier(svmkl_clf)\n",
    "param6 = { \n",
    "    'n_estimators': [100, 150],\n",
    "    'learning_rate': [0.5, 0.7]\n",
    "}\n",
    "\n",
    "grid6 = GridSearchCV(ada_skl, param6, cv= 5, n_jobs=-1)\n",
    "grid6.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters : {'learning_rate': 0.5, 'n_estimators': 100}\n",
      "Best score with the parameters : 0.7324\n"
     ]
    }
   ],
   "source": [
    "print('Best model parameters : ' + str(grid6.best_params_))\n",
    "print('Best score with the parameters : {:.4f}'.format(grid6.best_score_))\n",
    "ada_skl = grid6.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.7324\n",
      "Validation score: 0.7398\n"
     ]
    }
   ],
   "source": [
    "ada2_train_score = ada_skl.score(X_train, y_train)\n",
    "ada2_valid_score = ada_skl.score(X_valid, y_valid)\n",
    "print('Train score: {:.4f}'.format(ada2_train_score))\n",
    "print('Validation score: {:.4f}'.format(ada2_valid_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of SVM with Kernel Linear is: 0.7857\n",
      "The accuracy score of adaboost with SVM with Kernel Linear is: 0.7315\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy score of SVM with Kernel Linear is: {:.4f}\".format(svmkl_clf.score(X_test, y_test)))\n",
    "\n",
    "ada2_test_score = ada_skl.score(X_test, y_test)\n",
    "print(\"The accuracy score of adaboost with SVM with Kernel Linear is: {:.4f}\".format(ada2_test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Scores.append({'Model Type':'Classification',\n",
    "                    'Model Name': 'Adaboosting with SVM with Kernel Linear',\n",
    "                    'Best Parameters': grid6.best_params_,\n",
    "                    'Train Score': ada_skl.score(X_train, y_train),\n",
    "                    'Test Score': ada_skl.score(X_test, y_test)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Adaboost with SVM with Kernel Linear** gets a lower score **(0.7315)** than **SVM with Kernel Linear(0.7857)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=GradientBoostingClassifier(ccp_alpha=0.0,\n",
       "                                                  criterion='friedman_mse',\n",
       "                                                  init=None, learning_rate=0.1,\n",
       "                                                  loss='deviance', max_depth=3,\n",
       "                                                  max_features=None,\n",
       "                                                  max_leaf_nodes=None,\n",
       "                                                  min_impurity_decrease=0.0,\n",
       "                                                  min_impurity_split=None,\n",
       "                                                  min_samples_leaf=1,\n",
       "                                                  min_samples_split=2,\n",
       "                                                  min_weight_fraction_leaf=0.0,\n",
       "                                                  n_estimators=100,\n",
       "                                                  n_iter_no_change=None,\n",
       "                                                  presort='deprecated',\n",
       "                                                  random_state=None,\n",
       "                                                  subsample=1.0, tol=0.0001,\n",
       "                                                  validation_fraction=0.1,\n",
       "                                                  verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.3, 0.5, 0.7],\n",
       "                         'max_depth': [3, 5, 8],\n",
       "                         'n_estimators': [10, 50, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param7 = {\n",
    "    \"learning_rate\": [0.3, 0.5, 0.7],\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"n_estimators\":[10, 50, 100]\n",
    "    }\n",
    "\n",
    "grid7 = GridSearchCV(GradientBoostingClassifier(), param7, cv=5, n_jobs=-1)\n",
    "grid7.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters : {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 10}\n",
      "Best score with the parameters : 0.7982\n"
     ]
    }
   ],
   "source": [
    "print('Best model parameters : ' + str(grid7.best_params_))\n",
    "print('Best score with the parameters : {:.4f}'.format(grid7.best_score_))\n",
    "gb_clf = grid7.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8225\n",
      "Validation score: 0.7977\n"
     ]
    }
   ],
   "source": [
    "gb_train_score = gb_clf.score(X_train, y_train)\n",
    "gb_valid_score = gb_clf.score(X_valid, y_valid)\n",
    "print('Train score: {:.4f}'.format(gb_train_score))\n",
    "print('Validation score: {:.4f}'.format(gb_valid_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of Gradient Boosting is: 0.7966\n"
     ]
    }
   ],
   "source": [
    "gb_acu = gb_clf.score(X_test, y_test)\n",
    "print(\"The accuracy score of Gradient Boosting is: {:.4f}\".format(gb_acu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Scores.append({'Model Type':'Classification',\n",
    "                    'Model Name': 'Gradient Boosting',\n",
    "                    'Best Parameters': grid6.best_params_,\n",
    "                    'Train Score': gb_clf.score(X_train, y_train),\n",
    "                    'Test Score': gb_clf.score(X_test, y_test)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Gradient Boosting** gets a score of **0.7966**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Table of Task 1 to Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hard Voting Classifier</th>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>0.803189</td>\n",
       "      <td>0.797366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soft Voting Classifier</th>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>0.802927</td>\n",
       "      <td>0.791514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging with KNeighbor Classifier</th>\n",
       "      <td>Classification</td>\n",
       "      <td>{'max_samples': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>0.795609</td>\n",
       "      <td>0.782736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging with Decision Tree</th>\n",
       "      <td>Classification</td>\n",
       "      <td>{'max_samples': 0.5, 'n_estimators': 50}</td>\n",
       "      <td>0.794825</td>\n",
       "      <td>0.779078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pasting with Logistic Regression</th>\n",
       "      <td>Classification</td>\n",
       "      <td>{'max_samples': 0.7, 'n_estimators': 50}</td>\n",
       "      <td>0.800575</td>\n",
       "      <td>0.797366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pasting with Linear SVM</th>\n",
       "      <td>Classification</td>\n",
       "      <td>{'max_samples': 0.7, 'n_estimators': 50}</td>\n",
       "      <td>0.801098</td>\n",
       "      <td>0.795903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaboosting with Decision Tree</th>\n",
       "      <td>Classification</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>0.915055</td>\n",
       "      <td>0.750549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaboosting with SVM with Kernel Linear</th>\n",
       "      <td>Classification</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>0.732358</td>\n",
       "      <td>0.731529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>Classification</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>0.822530</td>\n",
       "      <td>0.796635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Model Type  \\\n",
       "Model Name                                                \n",
       "Hard Voting Classifier                   Classification   \n",
       "Soft Voting Classifier                   Classification   \n",
       "Bagging with KNeighbor Classifier        Classification   \n",
       "Bagging with Decision Tree               Classification   \n",
       "Pasting with Logistic Regression         Classification   \n",
       "Pasting with Linear SVM                  Classification   \n",
       "Adaboosting with Decision Tree           Classification   \n",
       "Adaboosting with SVM with Kernel Linear  Classification   \n",
       "Gradient Boosting                        Classification   \n",
       "\n",
       "                                                                     Best Parameters  \\\n",
       "Model Name                                                                             \n",
       "Hard Voting Classifier                                                                 \n",
       "Soft Voting Classifier                                                                 \n",
       "Bagging with KNeighbor Classifier          {'max_samples': 0.5, 'n_estimators': 100}   \n",
       "Bagging with Decision Tree                  {'max_samples': 0.5, 'n_estimators': 50}   \n",
       "Pasting with Logistic Regression            {'max_samples': 0.7, 'n_estimators': 50}   \n",
       "Pasting with Linear SVM                     {'max_samples': 0.7, 'n_estimators': 50}   \n",
       "Adaboosting with Decision Tree           {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "Adaboosting with SVM with Kernel Linear  {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "Gradient Boosting                        {'learning_rate': 0.5, 'n_estimators': 100}   \n",
       "\n",
       "                                         Train Score  Test Score  \n",
       "Model Name                                                        \n",
       "Hard Voting Classifier                      0.803189    0.797366  \n",
       "Soft Voting Classifier                      0.802927    0.791514  \n",
       "Bagging with KNeighbor Classifier           0.795609    0.782736  \n",
       "Bagging with Decision Tree                  0.794825    0.779078  \n",
       "Pasting with Logistic Regression            0.800575    0.797366  \n",
       "Pasting with Linear SVM                     0.801098    0.795903  \n",
       "Adaboosting with Decision Tree              0.915055    0.750549  \n",
       "Adaboosting with SVM with Kernel Linear     0.732358    0.731529  \n",
       "Gradient Boosting                           0.822530    0.796635  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame(model_Scores)\n",
    "table.set_index('Model Name', inplace = True)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The table above is the result table of models from **task 1 to task 4**:\n",
    "- We can see both **Hard Voting Classifier** and **Pasting with Logistic Regression** achieve the highest test score around 0.7974.\n",
    "- **Adaboosting with SVM with Kernel Linear** is underpreformance with a test score around 0.7315."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: PCA and Apply on all Project 1 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original train set components : 31\n",
      "Number of train set components after PCA with 95% feature information : 16\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95, random_state=0)\n",
    "\n",
    "X_train_r = pca.fit_transform(X_train)\n",
    "X_valid_r = pca.transform(X_valid)\n",
    "X_test_r = pca.transform(X_test)\n",
    "\n",
    "print('Number of original train set components : ' + str(X_train.shape[1]))\n",
    "print('Number of train set components after PCA with 95% feature information : ' + str(pca.n_components_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier 0.772\n",
      "LogisticRegression 0.778\n",
      "LogisticRegression 0.774\n",
      "LinearSVC 0.775\n",
      "SVC 0.764\n",
      "SVC 0.775\n",
      "SVC 0.767\n",
      "DecisionTreeClassifier 0.771\n"
     ]
    }
   ],
   "source": [
    "knn_pca = KNeighborsClassifier(18)\n",
    "log_pca = LogisticRegression(C=0.1, penalty='l2')\n",
    "sr_pca = LogisticRegression(multi_class='multinomial', solver='lbfgs', C=0.01)\n",
    "lsvm_pca = LinearSVC(C= 0.01)\n",
    "skl_pca = SVC(C=0.01, kernel='linear')\n",
    "srbf_pca = SVC(C=1, gamma=0.1, kernel='rbf')\n",
    "skp_pca = SVC(degree=3, C=0.1)\n",
    "dt_pca = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "for clf in (knn_pca, log_pca, sr_pca, lsvm_pca, skl_pca, srbf_pca, skp_pca, dt_pca):\n",
    "    clf.fit(X_train_r, y_train)\n",
    "    print(clf.__class__.__name__, round(clf.score(X_test_r, y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Project 1 Result Table <br>\n",
    "\n",
    "|No|Classifiers|Best Parameters|Original Score|PCA|\n",
    "|:--|:-----------|:---------------|:-------------|:----------|\n",
    "|1|KNN|k=18|0.774|0.772|\n",
    "|2|Logistic Regression|c = 0.1, penalty = l2|0.801|0.778|\n",
    "|3|Softmax Regression|c = 0.01|0.802|0.774|\n",
    "|4|Linear SVM|c = 0.01|0.803|0.775|\n",
    "|5|SVM with Kernel Linear|c=0.01|0.800|0.764| \n",
    "|6|SVM with Kernel RBF|c=1, gamma=0.1|0.800|0.775|\n",
    "|7|SVM with Kernel Polynomial|degree=3, c=0.1|0.798|0.767|\n",
    "|8|Decision Tree|depth=3|0.791|0.771|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After using PCA to reduce dimensions, test score of each model is decrease from around **0.80** to around **0.77**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3826, 31)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=31, activation=\"relu\"))\n",
    "    model.add(Dense(15, activation=\"relu\"))\n",
    "    model.add(Dense(10, activation=\"relu\"))\n",
    "    model.add(Dense(5, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss=\"mse\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "params = {'batch_size':[10, 20, 30, 40], 'epochs':[10, 50, 100]}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 30, 'epochs': 10}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = grid_search.best_params_['batch_size']\n",
    "epochs = grid_search.best_params_['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21196cdc5c8>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = grid_search.best_estimator_\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\qiuji\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8082\n",
      "Validation score: 0.8001\n",
      "Test score: 0.7959\n"
     ]
    }
   ],
   "source": [
    "print(\"Train score: {:.4f}\".format(accuracy_score(y_train, y_train_pred)))\n",
    "print(\"Validation score: {:.4f}\".format(accuracy_score(y_valid, y_valid_pred)))\n",
    "print(\"Test score: {:.4f}\".format(accuracy_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training the Neural Network using the original training dataset, we finally get the **test score: 0.7959**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
